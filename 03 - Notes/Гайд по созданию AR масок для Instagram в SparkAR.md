Используемый софт - **[[Spark AR|Meta Spark Studio (Spark AR)]]**.
Скачать программу можно по ссылке - [www.facebook.com/sparkarhub](http://www.facebook.com/sparkarhub)

**Нам понадобится VPN:**

1) Чтобы зайти на сайт и скачать Spark.

2) При первой авторизации.

3) При экспорте масок в Instagram. Работать в программе можно без VPN.

После установки перед нами открывается приветственное окно программы. В Spark Studio много пресетов, которыми можно пользоваться. Но для понимания процесса мы будем делать всё с нуля.

![Untitled](Untitled.png)

Разбирать процесс создания маски будем на этом примере:

![[ARStudioWindows_2FbfscfMVX.mp4]]

**ВАЖНО!** Рекомендую сразу же правильно называть все объекты, текстуры и материалы, т.к. чем больше их будет, тем проще в них запутаться.

Разобьём маску на составные части:

**1) Две анимированных секвенции с хлопушками и статичное лого. У них одинаковый принцип, поэтому считаем их за один элемент.**

**2) Затемняющий градиент**

**3) Петля, привязанная к лицу**

Пойдём по порядку от простого к сложному.

**Начнём с добавления анимированной секвенции, которая будет статично привязана к экрану.**

При создании **Blank** (пустого) проекта нас встречает интерфейс, который во многом похож на любой 3D пакет. В правом верхнем углу можно сразу подгрузить свой футаж, который предварительно нужно конвертировать в WebM формат. Я воспользовался этим сайтом - [https://cloudconvert.com/mov-to-webm](https://cloudconvert.com/mov-to-webm)

![Untitled](Untitled%201.png)

Для создания новых объектов в сцене используем плюсик к окне Scene менеджера. Нас интересует **Rectangle**, который представляет из себя статичную плоскость. С ним автоматически создаётся Canvas - контейнер для 2D объектов.

![Untitled](Untitled%202.png)

В окне редактирования объекта мы можем вручную задать значения длины/ширины и позиции объекта, а так же привязку к конкретным сторонам экрана (**Pinning**). Это важно, т.к. разные устройства имеют разные разрешения и если не выставить привязку - картинка может съезжать или зарезаться.

![Untitled](Untitled%203.png)

Также мы можем менять размер и позицию объекта напрямую во вьюпорте. 

![Untitled](Untitled%204.png)

Переходим к загрузке анимированной секвенции. Нас интересует плюсик во вкладке **Assets → Animation Sequence**.

![Untitled](Untitled%205.png)

В окне редактирования объекта выбираем **New Texture**, переходим в проводник, где выделяем все кадры, которые хотим подгрузить. 

![Untitled](Untitled%206.png)

Дальше переходим к созданию материала, который будем подгружать на 2D плоскость. 

![Untitled](Untitled%207.png)

В материале выбираем режим Flat, чтобы на него не действовали источники света и не искажались исходные цвета. В текстуру подгружаем нашу анимированную секвенцию.

![Untitled](Untitled%208.png)

Остаётся только накинуть материал на наш Rectangle объект.

![Untitled](Untitled%209.png)

Готово, мы создали анимированный эффект на маске. 

![Untitled](Untitled%2010.png)

**Дальше создадим градиент сверху.**

Его нам нужно создать внутри Spark, т.к. если подгрузить обычный PNG с градиентом - у нас будет лесенка.

Создаём отдельный Canvas с Rectangle внутри и ставим его выше секвенции. Иерархия в Spark сверху вниз, поэтому градиент должен лежать под анимированной хлопушкой.

![Untitled](Untitled%2011.png)

Кликнув по значениям мы можем выбрать **Fill Width** и **Fill Height**, чтобы полностью заполнить экран. Это нам и нужно.

![Untitled](Untitled%2012.png)

Дальше создаём новый материал, выставляем **Shader Type → Flat,** сразу накидываем его на **Rectangle** и нажимаем на галочку рядом с Texture.

![Untitled](Untitled%2013.png)

У нас открывается окно **Patch Editor**, в который добавляется нода материала градиента. Левым кликом по окну создаём ноды **Gradient** и **Gradient Step**. В Gradient выставляем Vertical, а в Gradient Step подбираем значения, которые нам подходят.

![Untitled](Untitled%2014.png)

Первый цвет будет чёрный **непрозрачный**.

![Untitled](Untitled%2015.png)

Второй - чёрный **прозрачный**. Это нужно для того, чтобы получить переход от черного к альфа каналу.

![Untitled](Untitled%2016.png)

Возвращаемся в материал и выставляем режим наложения Multiply с прозрачностью 80%.

![Untitled](Untitled%2017.png)

Готово, у нас есть градиент и анимированная хлопушка.

![Untitled](Untitled%2018.png)

**Переходим к самой сложной части - добавлению петли, которая будет огибать лицо и уходить за спину.**

По принципу создания градиента создаем отдельные Canvas и Rectangle, называем их Person. Выставляем **Fill Width** и **Fill Height**. Создаём Person материал с **Shader Type → Flat** и накидываем его на Rectangle.

Для корректной работы эффекта глубины нужно зайти **во все** материалы и убрать галки **Use Depth Test** и **Write to Depth Buffer** в Advanced Render Options. При создании новых важно не забывать убрать эти галки.

![Untitled](Untitled%2019.png)

Нажимаем на объект **Camera** в Scene менеджере и в настройках нажимаем плюсики у **Texture Extraction** и **Segmentation**. В Segmentation выбираем **Person**. У нас создаются 2 текстуры: **CameraTexture0** и **SegmentationMaskTexture0**, они нам нужны для того, чтобы отбить объект в кадре от фона.

![Untitled](Untitled%2020.png)

Переходим в материал Person. Применяем **CameraTexture0** в окно Texture. Включаем альфу и закидываем туда текстуру **segmentationMaskTexture0.**

![Untitled](Untitled%2021.png)

В окне вьюпорта можем заметить, что эффект уже работает. Если хотим, чтобы объект был перед лицом - ставим его ниже в иерархии, если сзади, соответственно - выше.

![Untitled](Untitled%2022.png)

Для создания эффекта глубины нам потребуются две секвенции. Одна полная, которая будет за объектом, и одна укороченная, которая будет спереди. У них должны совпадать FPS и количество кадров для корректного отображения.

![back.gif](back.gif)

![front.gif](front.gif)

Создаём две **Animation Sequence** с названиями **front_line** и **back_line**, подгружаем в них секвенции, аналогично тому, как делали при создании хлопушки. Создаём два **Plane** объекта и сразу правильно их называем. Отличие **Plane** от **Rectangle** в том, что его можно поворачивать в 3D пространстве.

![Untitled](Untitled%2023.png)

Размещаем **plane_back_line** выше в иерархии относительно **Person**, а **plane_front_line** выше.

![Untitled](Untitled%2024.png)

Создаём два материала **front_line** и **back_line**, выставляем **Shader Type → Flat**, подгружаем в них соответствующие текстуры. Не забываем убрать галочки с **Use Depth Test** и **Write to Depth Buffer**.

Мы можем одновременно менять значения для нескольких элементов. Для этого выделяем оба Plane и меняем значения Scale на 4, чтобы укрупнить объекты в кадре.

![Untitled](Untitled%2025.png)

Далее выбираем текстуру **segmentationMaskTexture0** и ставим **Edge Softness** на 50%, чтобы сделать края более жесткими.

![Untitled](Untitled%2026.png)

На этом этапе можем увидеть, что линия уже работает, **plane_front_line** мы видим перед лицом, а **plane_back_line** уходит за спину. Осталось привязать её к поворотам головы.

Для этого создаём объект **Face Tracker**, который будет отслеживать движения головы.

![Untitled](Untitled%2027.png)

Выделяем оба плейна и Person слой и закидываем в Face Tracker.

![Untitled](Untitled%2028.png)

Всё работает, можно нажать на иконку в правом нижнем углу экрана и протестировать как маска будет смотреться на разных устройствах.

![Untitled](Untitled%2029.png)

Если мы хотим передать маску другому человеку для дальнейшей доработки, в Spark AR заходим в меню **File** и выбираем **Package.** Так мы можем архивировать проект в специальный формат **.arprojpkg,** который можно просмотреть двойным кликом и распаковать как обычный архив через WinRAR.

![Untitled](Untitled%2030.png)

Переходим к оптимизации и тесту маски прям в Instagram. Нажимаем на кнопку **Test on device.** Для начала нужно выбрать нужный нам сценарий использования маски. Нажимаем **Add Experience.**

![Untitled](Untitled%2031.png)

В открывшемся окне снова нажимаем **Add Experience → Sharing Effect → Insert → Done.**

![Untitled](Untitled%2032.png)

Теперь мы можем снова нажать на кнопку **Test on Device** и отправить маску на тест себе в Instagram. На этом этапе необходимо включить VPN, т.к. необходимо подключение к серверам Facebook.

![Untitled](Untitled%2033.png)

Переходим к экспорту. Нажимаем кнопку **Publish.** Открывается окно экспорта, где мы можем загрузить демо-видео и проверить проходит ли маска по ограничениям Instagram **(4мб).** Для этого нажимаем на кнопку **View File Sizes.**

![Untitled](Untitled%2034.png)

Если в проекте используются тяжелые секвенции или картинки и суммарно маска весит больше **4мб** - нужно выбрать самые тяжёлые, поменять компрессию на **Manual** и покрутить настройки.

![Untitled](Untitled%2035.png)

Если маска подходит по весу - мы можем нажать кнопку **Upload** и загрузить её напрямую в Instagram, либо нажать **Export** и сохранить маску как **.arexport** файл и загрузить позже вручную через личный кабинет Facebook (предпочтительно).

Для того, чтобы опубликовать маску через Facebook - переходим по ссылке [www.facebook.com/sparkarhub](http://www.facebook.com/sparkarhub) со включенным VPN, нажимаем кнопку **Опубликовать.** Откроется окно, в котором можно загрузить файл **.arexport** и выбрать другие настройки публикации.

![Untitled](Untitled%2036.png)